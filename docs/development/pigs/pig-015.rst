.. include:: ../../references.txt

.. _pig-015:

***********************
PIG 15 - Data reduction
***********************

* Author: Axel Donath, Lars Mohrmann, RÃ©gis Terrier
* Created: June 30th, 2019
* Accepted:
* Status:
* Discussion:

Abstract
========
The data reduction also includes stacking


In general the responsibilities can be shared between the `MapDataset`
and e.g. a `MapMaker` class.


Introduction
============
One of the most important features of Gammapy are binned likelihood analyses.
To perform such an analysis, the event data as well as instrument response
functions must be prepared and binned into or reduced to a discrete data
structure (maps or spectra), with a binning specified by the user.
For analyses including O(1e2) - O(1e3) observations and a combined spatial
and spectral analysis this data reduction step can be computationally costly.
At the same time it should feature a simple and flexible user interface.

Typically the reduced data is computed per observation or per time interval
and possibly includes further selection of events, such as phase or type.


The main analysis classes for likelihood fitting in Gammapy are the
`MapDataset` and `SpectrumDataset` objects. A natural extension of
the dataset concept is to implement algorithmic classes, that are
responsible for the preparation and data reduction and return
pre-filled dataset objects.


Beside the reduction of the selected data, it must be a also



What we currently have:


`MapMaker`

`MapMakerRing`

`MapMakerObs`


`make_mean_psf()`,
`make_mean_edisp()`,
`make_psf`,
`IRFStacker`


`SpectrumExtraction`
`SpectrumDatasetOnOffStacker`


Background estimators:


Work on maps:

`RingBackgroundEstimator`,
`AdaptiveRingBackgroundEstimator`,


Work on event lists:

`ReflectedRegionsBackgroundEstimator`,
`PhaseBackgroundEstimator`



Proposal
========


Overview


The general proposed work-flow for data reduction is as follows:

- Choose MapGeom for counts and background
- Choose MapGeom for exposure, PSFMap and EDispMap
_ Compute a dataset per observation, compute safe mask, but don't apply. This
give users the possibility to change the safe data range later.
- Safe mask is only applied for stacking and during fitting.

Introduce `MapDataset.to_image()` to sum over energy axes and compute weighted
exposure and PSF maps?


Adding `Dataset.create()` methods
--------------------------
First we propose to add `.create()` methods to the existing `MapDataset`,
`SpectrumDataset` and `SpectrumDatasetOnOff` class. The purpose is to make it
easy to create empty datasets, which can be filled via stacking.


.. code::

    dataset = MapDataset.from(geom, geom_irf)
    spectrum_dataset = SpectrumDataset.create(geom, geom_irf)


Adding `Dataset.stack()` methods
--------------------------------
To allow for flexible stacking of datasets we propose to add `.stack()` methods
to the existing `MapDataset`, `SpectrumDataset` and `SpectrumDatasetOnOff` classes.

A typical example for stacking of datasets like:

.. code::

    dataset_stacked = MapDataset.create(geom, geom_irf)

    for dataset in datasets:
        dataset_stacked.stack(dataset)


For now we assume that only datasets with compatible bin-sizes and aligned WCS
or HPX representations can be stacked. Later we could add the possibility to
stack non-aligned data structures by introducing an additional interpolation
step (see outlook).

The stacking is performed in-place, which is more memory efficient.

We also propose to extende this concept to IRF and Map classes. This includes:

- `EnergyDispersion.stack()`
- `PSFKernel.stack()`
- `Map.stack()` or `Map.paste()`


`MapDatasetMaker`
-----------------
Re-use FoV coordinates, share code for time-averaging, etc.

Aligned WCS projections between "global" and cutouts...

Similar to `MapMakerObs`, adds computation of edisp and psf maps.

Assume same geom for counts and background,



ObservationFilter? Where is the offset_max configured?


Start with `MapDataset.create()`?

.. code::

    maker = MapDatasetMaker(geom, energy_axis_true, migra_axis, rad_axis, binsz_irf, source_position?)
    maker = MapDatasetMaker(geom, geom_true, geom_psf, geom_edisp, source_position?)


    dataset = maker.run(obs, steps=["counts", "background", "exposure", "psf", "edisp"]])


    dataset = MapDataset.create(geom, ..., )

    for obs in observations:
        cutout = dataset.cutout(width=offset_max?)
        maker = MapDatasetMaker(cutout, )
        dataset = maker.run(obs)


Should the `DatasetMaker` split into time-intervals?

    for obs in observations:

        maker = MapDatasetMaker(time_intervals=[]?)
        datasets = maker.run(obs)


Or make the cut out in `.run()`?


.. code::

    # what about observation filter, such as FoV cut?
    maker_safe = SafeMaskMaker(offset_max, energy_threshold, method, filter, ...)
    dataset = mask_safe.run(dataset)


MapDatasetMaker -> SafeMaskMaker -> BackgroundMaker

Allow for PSF  EDISP maps as well as extraction of a singke PSF/ EDISP at a given source position.


`SpectrumDatasetMaker`
----------------------

.. code::

    maker = SpectrumDatasetMaker(on_region, energy_reco, energy_true)

    dataset = maker.run(obs, steps=["counts", "background", "exposure", "psf", "edisp"])


    maker_safe = SafeMaskMaker(energy_threshold, method, filter, ...)?
    dataset = maker_safe.run(dataset)




`Map Background Estimators`
---------------------------
Registry for background estimators? Config from high level interface?


Reflected, ring, adaptive ring etc.


Supports 3D, merge adaptive and non-adaptive into one class.



.. code::

    bkg_maker = FoVBackgroundMaker(exclusion_mask=, method=, ...)

    map_dataset = bkg_maker.run(dataset)


Fit background norm and tilt...how to keep track the background model parameters?
Store it in the FITS meta?
Write a default yaml model file?


.. code::

    bkg_maker = RingBackgroundMaker(r_in, r_out, ..., exclusion_mask,  adaptive=True)

    map_dataset_onoff = bkg_maker.run(map_dataset)




`ReflectedRegionsBackgroundMaker`
---------------------------------

.. code::

    bkg_maker = ReflectedRegionBackgroundMaker()

    spectrum_dataset_onoff = bkg_maker.run(obs)




Use case of light curves:
- Estimate background from full length observation, while the on counts are extracted in
time intervals
-





`DatasetsMaker`?
-------------------
Loop over observations, parallelisation, bookkeeping, convenience?


.. code::

    maker = DatasetsMaker(dataset_maker=, background_maker=, safe_mask_maker=, time_intervals=?)
    maker = DatasetsMaker(dataset_maker_config={}, background_maker_config={}, safe_mask_maker_config={}, time_intervals=?)

    datasets = maker.run(observations, n_jobs=4)

    maker.run_write(observations)


    dataset = maker.run_stack(observations)


    dataset = maker.stack(datasets)
    dataset = datasets.stack()








`.stack(datasets)`
`.read_stack(filenames, obs_ids)`

`.run(obervations)`
`.run_write(observations)`






Outlook
=======
Change DL3 data format to precomputed background, exposure, edisp and psf maps?
What about `MapDataset.to_spectrum_dataset(region, )`?





What to do about real On / Off observations?

.. code::

    bkg_maker = OffBackgroundMaker()

    dataset_on_off = bkg_maker.run(dataset, obs_off)

    # dataset_on_off = bkg_maker.run(dataset, [dataset_off, ])


A simple 1:1 correspondence could be implemented like shown above. How to handle
the off observation list.

Alternatively handle it on the dataset level by passing an already reduce off dataset...

Requires FoV coordinates for maps...

It's complicated...



Task List
=========
We propose to implement the functionality via the following pull requests:

1. Implement `MapDatasetEstimator`
2. Implement `DatasetsEstimator`
3. Implement `MapDataset.stack()` method
4. Implement `SpectrumDatasetOnOff.stack()` method
5. Implement `EnergyDispersion.stack()` method




Decision
========


